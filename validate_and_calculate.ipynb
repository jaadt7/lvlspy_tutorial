{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is structured to read levels from an xml and perform sample calculations. We start off by installing any missing packages this notebook will need to fully run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess, pkg_resources\n",
    "required = {'numpy','lvlspy','matplotlib','scipy'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "if missing:\n",
    "    subprocess.check_call([sys.executable, '-m','pip','install','--quiet',*missing])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import lvlspy.level as lv\n",
    "import lvlspy.spcoll as lc\n",
    "import lvlspy.species as ls\n",
    "import lvlspy.transition as lt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import expm_multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by downloading an example xml file, called, appropriately enough, *example.xml*, from [OSF](https://osf.io/3f59u/).  You may instead place or upload your own file and use it by commenting out the *curl* command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o example.xml -J -L https://osf.io/w6ndg/download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by creating a new species collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coll = lc.SpColl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now ensure that the data in *example.xml* are appropriate to use with *lvlspy* by validating the XML file against the appropriate liblvls schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coll.validate('example.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the data into the species collection by updating the (empty) collection with data from the XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coll.update_from_xml('example.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the species from the collection and set a temperature (in Kelvin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = new_coll.get()['my_species']\n",
    "T = 1.e+9 #K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the stored properties in the xml, energies, Einstein A coefficients, and multiplicities, with the supplied temperature, we can calculate the rate matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_matrix = sp.compute_rate_matrix(T)\n",
    "\n",
    "print('\\nRate Matrix:\\n')\n",
    "\n",
    "for i in range(rate_matrix.shape[0]):\n",
    "    for j in range(rate_matrix.shape[1]):\n",
    "        print(i, j, rate_matrix[i, j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following exercises can be done by going through the steps of the other notebook without having to import an xml, but for the sake of flexing the API's power, this is the route we chose. Since we have a rate matrix, we can now evolve our species with time at a fixed temperature. The governing differential equation is $\\frac{dY}{dt} = \\Lambda Y$. The integrator for this system of 5 coupled equations is the Newton-Raphson method, a full description can be found at [webnucleo.org](https://webnucleo.readthedocs.io/en/latest/jupyter_notebooks.html).\n",
    "\n",
    "The following definition calculates the vector f in the equation $A\\delta = -f$ and the matrix A itself is updated with the time step. The following contains the setup and loop for the Newton-Raphson solver. If you are unfamiliar with the method, it is fully described "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_vector(y_dt,y_i,A):\n",
    "    return np.matmul(A,y_dt) - y_i\n",
    "\n",
    "def newt_raf(y,dt,tol,rate_matrix):\n",
    "    y_dt = y\n",
    "    A = np.identity(len(y_dt)) - dt*rate_matrix\n",
    "    delta = np.ones(len(y_dt))\n",
    "    while max(delta) > tol:\n",
    "        delta = np.linalg.solve(A,-f_vector(y_dt,y,A))\n",
    "        y_dt = y_dt + delta\n",
    "\n",
    "    return y_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sets up the time array, initial condition, and convergence tolerance to run the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol =1e-6 #convergence tolerance\n",
    "t_begin = 1.e-30\n",
    "t_end = 100\n",
    "n_steps = 200\n",
    "\n",
    "y = np.zeros(rate_matrix.shape[0]) #initial condition. default is system sitting at level 0\n",
    "y[0] = 1.0\n",
    "t = np.logspace(np.log10(t_begin), np.log10(t_end), n_steps) #logarithmic space was chosen to smoothen out the graphs at small timescales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the main loop that runs the Newton-Raphson method to evolve the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.empty((5,n_steps)) #set up the 2D array for graphing\n",
    "Y[:,0] = y #initialize the 1st column to the initial conditions set above\n",
    "\n",
    "for i in range(1,n_steps):\n",
    "    dt = t[i] - t[i-1] #since we are using logspace for time, the timestep is not constant\n",
    "    Y[:,i] = newt_raf(y,dt,tol,rate_matrix)\n",
    "    y = Y[:,i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API can also calculate the equilibrium values beforehand. The starred values on the graph are the equilibrium values calculated straight from the API. As expected, the system evolved towards those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_probs = sp.compute_equilibrium_probabilities(T)\n",
    "\n",
    "for i in range(len(sp.get_levels())):\n",
    "    plt.plot(t,Y[i,:],label = str(i) + ' level')\n",
    "        \n",
    "plt.gca().set_prop_cycle(None)  # Reset the color cycle to align equilibria with network solutions.\n",
    "\n",
    "for i in range(len(eq_probs)):\n",
    "    plt.plot(t_end, eq_probs[i], 'x')\n",
    "    \n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('Probability')\n",
    "plt.xlim([1e-8,1000])\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good exercise to tweak the initial condition set above and rerun the cells to verify that the system will always evolve to the equilibrium values. Just remember to normalize the vector since these values are probabilities. For those who want a more 'built-in', you can easily use odeint or sparse solving techniques built into scipy. \n",
    "\n",
    "We'll start with odeint, for both we will use the same time setup as defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(y, t, rate_matrix): #this function calculates the derivatives\n",
    "    return rate_matrix.dot(y)\n",
    "\n",
    "y = np.zeros(rate_matrix.shape[0]) #initial conditions\n",
    "y[0] = 1\n",
    "\n",
    "sol_odeint = odeint(my_func, y, t, args=(rate_matrix,))\n",
    "\n",
    "#graph\n",
    "for i in range(sol_odeint.shape[1]):\n",
    "    plt.plot(t, sol_odeint[:, i], label = 'Level ' + str(i))\n",
    "    \n",
    "plt.gca().set_prop_cycle(None)  # Reset the color cycle to align equilibria with network solutions.\n",
    "\n",
    "for i in range(sol_odeint.shape[1]):\n",
    "    plt.plot(t[t.shape[0]-1], eq_probs[i], 'x')\n",
    "    \n",
    "plt.xscale('log')\n",
    "plt.xlim([1.e-10, 1000])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the sparse solver. The method built into scipy is called expm_multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(rate_matrix.shape[0]) #initial conditions\n",
    "y[0] = 1\n",
    "\n",
    "A = csc_matrix(rate_matrix) #transforming the rate matrix into its sparse form\n",
    "\n",
    "sol_expm_solver = np.empty([t.shape[0], rate_matrix.shape[0]])\n",
    "sol_expm_solver[0,:] = y\n",
    "for i in range(len(t)-1):\n",
    "    y = expm_multiply(A, y, start=t[i], stop=t[i+1], num=2, endpoint=True)[0,:]\n",
    "    sol_expm_solver[i+1,:] = y\n",
    "\n",
    "for i in range(sol_expm_solver.shape[1]):\n",
    "    plt.plot(t, sol_expm_solver[:, i], label = 'Level ' + str(i))\n",
    "    \n",
    "plt.gca().set_prop_cycle(None)  # Reset the color cycle to align equilibria with network solutions.\n",
    "\n",
    "for i in range(sol_expm_solver.shape[1]):\n",
    "    plt.plot(t[t.shape[0]-1], eq_probs[i], 'x')\n",
    "    \n",
    "plt.xscale('log')\n",
    "plt.xlim([1.e-10, 1000])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the three graphs are identitcal. The fugacity evolution of each level can be calculated based on the attained solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fugacities = np.empty((Y.shape[0], Y.shape[1]))\n",
    "\n",
    "for i in range(len(sp.get_levels())):\n",
    "    fugacities[i, :] = Y[i, :] / eq_probs[i]\n",
    "    \n",
    "for i in range(len(sp.get_levels())):\n",
    "    plt.plot(t,fugacities[i,:],label = str(i) + ' level')\n",
    "    \n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('Fugacity')\n",
    "plt.xscale('log')\n",
    "plt.xlim([1e-6,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step to illustrate another *SpColl* method, output the data in the species collection to new files.  The first uses the default energy scale (*keV*) while the second specifically selects *eV* as the energy scale for the levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coll.write_to_xml(\"new_example.xml\")\n",
    "\n",
    "new_coll.write_to_xml(\"new_example_ev.xml\", units = 'eV')\n",
    "\n",
    "!cat new_example_ev.xml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
